{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_list = []\n",
    "\n",
    "input_dir = \"/home/de-admin/Documents/open data/wikipedia pickle/\"\n",
    "output_dir = \"/home/de-admin/Documents/open data/wikipedia final pickle/\"\n",
    "\n",
    "for pickle in os.listdir(input_dir):\n",
    "    pickle_list.append(pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import mwparserfromhell\n",
    "import lxml\n",
    "from lxml import html, etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpickle data to process for NLP. File 35\n",
      "NLP Preparation. File 35\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Re-pickle data. File 35\n",
      "Unpickle data to process for NLP. File 36\n",
      "NLP Preparation. File 36\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Re-pickle data. File 36\n",
      "Unpickle data to process for NLP. File 37\n",
      "NLP Preparation. File 37\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Re-pickle data. File 37\n",
      "Unpickle data to process for NLP. File 38\n",
      "NLP Preparation. File 38\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Re-pickle data. File 38\n",
      "Unpickle data to process for NLP. File 39\n",
      "NLP Preparation. File 39\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "list index out of range\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Observation: 350000\n",
      "Re-pickle data. File 39\n",
      "Unpickle data to process for NLP. File 40\n",
      "NLP Preparation. File 40\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Observation: 350000\n",
      "Re-pickle data. File 40\n",
      "Unpickle data to process for NLP. File 41\n",
      "NLP Preparation. File 41\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Observation: 350000\n",
      "Re-pickle data. File 41\n",
      "Unpickle data to process for NLP. File 42\n",
      "NLP Preparation. File 42\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Re-pickle data. File 42\n",
      "Unpickle data to process for NLP. File 43\n",
      "NLP Preparation. File 43\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Re-pickle data. File 43\n",
      "Unpickle data to process for NLP. File 44\n",
      "NLP Preparation. File 44\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Re-pickle data. File 44\n",
      "Unpickle data to process for NLP. File 45\n",
      "NLP Preparation. File 45\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Re-pickle data. File 45\n",
      "Unpickle data to process for NLP. File 46\n",
      "NLP Preparation. File 46\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Observation: 350000\n",
      "Re-pickle data. File 46\n",
      "Unpickle data to process for NLP. File 47\n",
      "NLP Preparation. File 47\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Observation: 350000\n",
      "Re-pickle data. File 47\n",
      "Unpickle data to process for NLP. File 48\n",
      "NLP Preparation. File 48\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Re-pickle data. File 48\n",
      "Unpickle data to process for NLP. File 49\n",
      "NLP Preparation. File 49\n",
      "Observation: 0\n",
      "Re-pickle data. File 49\n",
      "Unpickle data to process for NLP. File 50\n",
      "NLP Preparation. File 50\n",
      "Observation: 0\n",
      "Re-pickle data. File 50\n",
      "Unpickle data to process for NLP. File 51\n",
      "NLP Preparation. File 51\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Re-pickle data. File 51\n",
      "Unpickle data to process for NLP. File 52\n",
      "NLP Preparation. File 52\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Re-pickle data. File 52\n",
      "Unpickle data to process for NLP. File 53\n",
      "NLP Preparation. File 53\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Observation: 300000\n",
      "Observation: 350000\n",
      "Re-pickle data. File 53\n",
      "Unpickle data to process for NLP. File 54\n",
      "NLP Preparation. File 54\n",
      "Observation: 0\n",
      "Observation: 50000\n",
      "Observation: 100000\n",
      "Observation: 150000\n",
      "Observation: 200000\n",
      "Observation: 250000\n",
      "Re-pickle data. File 54\n"
     ]
    }
   ],
   "source": [
    "text_to_remove = [\"#REDIRECT\", \"#redirect\", \"#Redirect\"]\n",
    "\n",
    "punctuation = str.maketrans('', '', string.punctuation)\n",
    "stop_words = stopwords.words('english')\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "i=35\n",
    "#j=45\n",
    "\n",
    "for file in pickle_list[i:]:\n",
    "    clean_list = []\n",
    "    print(\"Unpickle data to process for NLP. File %s\" % str(i))\n",
    "    pickle_part = pickle.load(open(input_dir+file, \"rb\" ))\n",
    "\n",
    "    print(\"NLP Preparation. File %s\" % str(i))\n",
    "    k = 0\n",
    "    for doc in pickle_part:\n",
    "        \n",
    "        get_bit = 1\n",
    "        cat_links = []\n",
    "        \n",
    "        try:\n",
    "            doc_txt = html.fromstring(doc[1]).xpath('//text//text()')[0]\n",
    "\n",
    "            for ttr in text_to_remove:\n",
    "                if ttr in doc_txt:\n",
    "                    get_bit = 0            \n",
    "                elif \"(disambiguation)\" in doc[0]:\n",
    "                    get_bit = 0\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            get_bit = 0\n",
    "\n",
    "        if get_bit == 1:\n",
    "            for link in mwparserfromhell.parse(html.fromstring(doc[1]).xpath('//text//text()')).filter_wikilinks():\n",
    "                if \"Category:\" in link:\n",
    "                    cat_links.append(link)   \n",
    "            doc_par = mwparserfromhell.parse(doc_txt).filter_text()\n",
    "            doc_str = ' '.join(str(s) for s in doc_par) \n",
    "            words = [lem.lemmatize(w.lower(), \"v\") for w in doc_str.split()]\n",
    "            doc_clean = list(filter(None, [w.translate(punctuation) for w in words]))\n",
    "            doc_filtered = [word for word in doc_clean if word not in stop_words]\n",
    "            clean_list.append([doc[0],' '.join(doc_filtered),cat_links])\n",
    "\n",
    "        if k % 50000 == 0:\n",
    "            print(\"Observation: %s\" % str(k))\n",
    "            \n",
    "        k = k + 1\n",
    "    \n",
    "    print(\"Re-pickle data. File %s\" % str(i))\n",
    "    pickle_file = output_dir+file\n",
    "    pickle.dump(clean_list, open(pickle_file, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
