{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompress and Cleanse Wikifiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_list = []\n",
    "\n",
    "input_dir = \"/home/de-admin/Documents/open data/wikipedia bzips/\"\n",
    "output_dir = \"/home/de-admin/Documents/open data/wikipedia txt/\"\n",
    "\n",
    "for zips in os.listdir(input_dir):\n",
    "    zip_list.append(zips[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "from lxml import html, etree\n",
    "import mwparserfromhell\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 30\n",
      "Parsing text 30\n",
      "Pickling dataset 30\n",
      "Deleting interrim dataset 30\n",
      "Processing file 31\n",
      "Parsing text 31\n",
      "Pickling dataset 31\n",
      "Deleting interrim dataset 31\n",
      "Processing file 32\n",
      "Parsing text 32\n",
      "Pickling dataset 32\n",
      "Deleting interrim dataset 32\n",
      "Processing file 33\n",
      "Parsing text 33\n",
      "Pickling dataset 33\n",
      "Deleting interrim dataset 33\n",
      "Processing file 34\n",
      "Parsing text 34\n",
      "Pickling dataset 34\n",
      "Deleting interrim dataset 34\n",
      "Processing file 35\n",
      "Parsing text 35\n",
      "Pickling dataset 35\n",
      "Deleting interrim dataset 35\n",
      "Processing file 36\n",
      "Parsing text 36\n",
      "Pickling dataset 36\n",
      "Deleting interrim dataset 36\n",
      "Processing file 37\n",
      "Parsing text 37\n",
      "Pickling dataset 37\n",
      "Deleting interrim dataset 37\n",
      "Processing file 38\n",
      "Parsing text 38\n",
      "Pickling dataset 38\n",
      "Deleting interrim dataset 38\n",
      "Processing file 39\n",
      "Parsing text 39\n",
      "Pickling dataset 39\n",
      "Deleting interrim dataset 39\n",
      "Processing file 40\n",
      "Parsing text 40\n",
      "Pickling dataset 40\n",
      "Deleting interrim dataset 40\n",
      "Processing file 41\n",
      "Parsing text 41\n",
      "Pickling dataset 41\n",
      "Deleting interrim dataset 41\n",
      "Processing file 42\n",
      "Parsing text 42\n",
      "Pickling dataset 42\n",
      "Deleting interrim dataset 42\n",
      "Processing file 43\n",
      "Parsing text 43\n",
      "Pickling dataset 43\n",
      "Deleting interrim dataset 43\n",
      "Processing file 44\n",
      "Parsing text 44\n",
      "Pickling dataset 44\n",
      "Deleting interrim dataset 44\n",
      "Processing file 45\n",
      "Parsing text 45\n",
      "Pickling dataset 45\n",
      "Deleting interrim dataset 45\n",
      "Processing file 46\n",
      "Parsing text 46\n",
      "Pickling dataset 46\n",
      "Deleting interrim dataset 46\n",
      "Processing file 47\n",
      "Parsing text 47\n",
      "Pickling dataset 47\n",
      "Deleting interrim dataset 47\n",
      "Processing file 48\n",
      "Parsing text 48\n",
      "Pickling dataset 48\n",
      "Deleting interrim dataset 48\n",
      "Processing file 49\n",
      "Parsing text 49\n",
      "Pickling dataset 49\n",
      "Deleting interrim dataset 49\n",
      "Processing file 50\n",
      "Parsing text 50\n",
      "Pickling dataset 50\n",
      "Deleting interrim dataset 50\n",
      "Processing file 51\n",
      "Parsing text 51\n",
      "Pickling dataset 51\n",
      "Deleting interrim dataset 51\n",
      "Processing file 52\n",
      "Parsing text 52\n",
      "Pickling dataset 52\n",
      "Deleting interrim dataset 52\n",
      "Processing file 53\n",
      "Parsing text 53\n",
      "Pickling dataset 53\n",
      "Deleting interrim dataset 53\n",
      "Processing file 54\n",
      "Parsing text 54\n",
      "Pickling dataset 54\n",
      "Deleting interrim dataset 54\n"
     ]
    }
   ],
   "source": [
    "pages_to_keep = [\"Category:\"]\n",
    "\n",
    "i=30\n",
    "#j=30\n",
    "\n",
    "for zips in zip_list[i:]:\n",
    "#for zips in zip_list[i:j]:\n",
    "    print(\"Processing file %s\" % str(i))\n",
    "    filepath = os.path.join(input_dir, zips + \".bz2\")\n",
    "    newfilepath = os.path.join(output_dir, zips)\n",
    "    \n",
    "    with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
    "        for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "            new_file.write(data)    \n",
    "    \n",
    "    print(\"Parsing text %s\" % str(i))\n",
    "    \n",
    "    wikitext = open(newfilepath, encoding='utf-8')\n",
    "    \n",
    "    output = []\n",
    "    text = \"\"\n",
    "    title = \"\"\n",
    "    get_bit = 0\n",
    "    \n",
    "    with wikitext as wt:\n",
    "        for line in wt:          \n",
    "            if \"</page>\" in line:\n",
    "                if get_bit == 1:\n",
    "                    text = text + \" \" + line\n",
    "                    try:\n",
    "                        if get_bit == 1:\n",
    "                            output.append([title, text])\n",
    "                    except:\n",
    "                        print(text)\n",
    "                get_bit = 0\n",
    "            elif \"<page>\" in line: \n",
    "                text = \"<page>\"\n",
    "                title = \"\"\n",
    "            elif \"<title>\" in line:\n",
    "                text = text + \" \" + line\n",
    "                title = etree.fromstring(str(mwparserfromhell.parse(line))).xpath('//title//text()')[0]\n",
    "                for ptk in pages_to_keep:\n",
    "                    if title.startswith(ptk):\n",
    "                        get_bit = 1\n",
    "            elif get_bit == 1:\n",
    "                text = text + \" \" + line                \n",
    "\n",
    "    print(\"Pickling dataset %s\" % str(i))\n",
    "    \n",
    "    pickle_file = \"/home/de-admin/Documents/open data/wikipedia category pickle/category\"+str(i)+\".p\"\n",
    "    pickle.dump(output, open(pickle_file, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "    print(\"Deleting interrim dataset %s\" % str(i))\n",
    "    \n",
    "    os.remove(newfilepath)\n",
    "    \n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
